import streamlit as st
import pandas as pd
import numpy as np
import requests
from bs4 import BeautifulSoup
import re
from datetime import datetime
import json

st.set_page_config(page_title="GerÃ§ek Enflasyon Sepeti", layout="wide", page_icon="ğŸ‡¹ğŸ‡·")

st.title("ğŸ‡¹ğŸ‡· KapsamlÄ± Enflasyon Veri Madencisi")
st.markdown("**Kaynak:** `enf_veri_cekme_guncel.ipynb` (Orijinal Kod) | **Kapsam:** `12 Ana Harcama Grubu`")

# --- ORTAK FONKSÄ°YONLAR ---
def get_soup(url):
    headers = {"User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36"}
    try:
        response = requests.get(url, headers=headers, timeout=15)
        response.raise_for_status()
        return BeautifulSoup(response.content, "html.parser")
    except:
        return None

def clean_price(price_str):
    if not price_str: return 0.0
    try:
        clean = str(price_str).replace('â‚º', '').replace('TL', '').strip()
        if "," in clean and "." in clean: clean = clean.replace('.', '').replace(',', '.')
        elif "," in clean: clean = clean.replace(',', '.')
        return float(clean)
    except:
        return 0.0

# --- 1. GIDA VE ALKOLSÃœZ Ä°Ã‡ECEKLER ---
def fetch_gida():
    st.info("ğŸ… 1. GÄ±da ve Market verileri Ã§ekiliyor... (Onur Market)")
    gida_dict = {
        "Sebze": ["https://www.onurmarket.com/domates-kg--8126", "https://www.onurmarket.com/biber-carliston-kg--8101", "https://www.onurmarket.com/sogan-kuru-dokme-kg--8102"],
        "Meyve": ["https://www.onurmarket.com/ithal-muz-kg", "https://www.onurmarket.com/elma-starking-kg--7896"],
        "Et/SÃ¼t": ["https://www.onurmarket.com/-ksp.et-dana-antrikot-kg--121", "https://www.onurmarket.com/butun-pilic-kg", "https://www.onurmarket.com/pinar-sut-25-yagli-1-lt-115056"],
        "Temel": ["https://www.onurmarket.com/-komili-aycicek-pet-4-lt--69469", "https://www.onurmarket.com/-caykur-tiryaki-1000-gr--3947"]
    }
    data = []
    for kat, urls in gida_dict.items():
        for url in urls:
            soup = get_soup(url)
            fiyat = 0
            isim = "ÃœrÃ¼n BulunamadÄ±"
            if soup:
                isim_tag = soup.find("div", class_="ProductName")
                if isim_tag: isim = isim_tag.find("h1").get_text(strip=True)
                fiyat_tag = soup.find("span", class_="spanFiyat")
                if fiyat_tag: fiyat = clean_price(fiyat_tag.get_text())
            data.append({"Grup": "GÄ±da", "Kategori": kat, "ÃœrÃ¼n": isim, "Fiyat": fiyat})
    return pd.DataFrame(data)

# --- 2. GÄ°YÄ°M VE AYAKKABI ---
def fetch_giyim():
    st.info("ğŸ‘• 2. Giyim ve AyakkabÄ± verileri Ã§ekiliyor... (Koton & Flo)")
    # Koton (Giyim)
    koton_urls = [
        "https://www.koton.com/pamuklu-slim-fit-uzun-kollu-italyan-yaka-gomlek-lacivert-4022961-2/",
        "https://www.koton.com/straight-fit-kot-pantolon-mark-jean-siyah-3956949/"
    ]
    # Flo (AyakkabÄ±)
    flo_urls = [
        "https://www.flo.com.tr/urun/inci-acel-4fx-kahverengi-erkek-klasik-ayakkabi-101544485",
        "https://www.flo.com.tr/urun/adidas-erkek-spor-ayakkabi-id7110-201257192"
    ]
    data = []
    
    # Koton Loop
    for url in koton_urls:
        soup = get_soup(url)
        fiyat = 0; isim = "Koton ÃœrÃ¼n"
        if soup:
            isim_tag = soup.find("h1", class_="product-info__header-title")
            if isim_tag: isim = isim_tag.get_text(strip=True)
            fiyat_tag = soup.find("div", class_="product-price__price") # SÄ±nÄ±f deÄŸiÅŸmiÅŸ olabilir, kontrol ÅŸart
            if not fiyat_tag: fiyat_tag = soup.find("div", class_="price__price")
            if fiyat_tag: fiyat = clean_price(fiyat_tag.get_text())
        data.append({"Grup": "Giyim", "Kategori": "KÄ±yafet", "ÃœrÃ¼n": isim, "Fiyat": fiyat})

    # Flo Loop
    for url in flo_urls:
        soup = get_soup(url)
        fiyat = 0; isim = "Flo AyakkabÄ±"
        if soup:
            isim_tag = soup.find("h1", class_="product-detail-name") # SÄ±nÄ±flar dinamik olabilir
            if not isim_tag: isim_tag = soup.find("span", class_="js-product-name")
            if isim_tag: isim = isim_tag.get_text(strip=True)
            
            fiyat_tag = soup.find("div", class_="product-price__current-price")
            if not fiyat_tag: fiyat_tag = soup.find("div", class_="product-pricing-one__price")
            if fiyat_tag: fiyat = clean_price(fiyat_tag.get_text())
        data.append({"Grup": "Giyim", "Kategori": "AyakkabÄ±", "ÃœrÃ¼n": isim, "Fiyat": fiyat})
        
    return pd.DataFrame(data)

# --- 3. EV EÅYASI (Mobilya, Beyaz EÅŸya) ---
def fetch_ev():
    st.info("ğŸ›‹ï¸ 3. Ev EÅŸyasÄ± verileri Ã§ekiliyor... (Ä°stikbal & ArÃ§elik)")
    # Ä°stikbal
    istikbal_url = "https://www.istikbal.com.tr/urun/briella-yemek-odasi-takimi"
    # ArÃ§elik
    arcelik_url = "https://www.arcelik.com.tr/statik-buzdolabi/d-154140-mb-buzdolabi"
    
    data = []
    
    # Ä°stikbal
    s1 = get_soup(istikbal_url)
    f1 = 0; i1 = "Yemek OdasÄ±"
    if s1:
        t = s1.find("div", class_="product-title")
        if t: i1 = t.get_text(strip=True)
        p = s1.find("div", class_="product-price-new")
        if p: f1 = clean_price(p.get_text())
    data.append({"Grup": "Ev EÅŸyasÄ±", "Kategori": "Mobilya", "ÃœrÃ¼n": i1, "Fiyat": f1})
    
    # ArÃ§elik (JSON-LD YÃ¶ntemi - Senin kodundaki gibi)
    s2 = get_soup(arcelik_url)
    f2 = 0; i2 = "BuzdolabÄ±"
    if s2:
        script = s2.find("script", type="application/ld+json")
        if script:
            try:
                js = json.loads(script.string)
                i2 = js.get("name", i2)
                f2 = clean_price(str(js.get("offers", {}).get("price", 0)))
            except: pass
    data.append({"Grup": "Ev EÅŸyasÄ±", "Kategori": "Beyaz EÅŸya", "ÃœrÃ¼n": i2, "Fiyat": f2})
    
    return pd.DataFrame(data)

# --- 4. ULAÅTIRMA (YakÄ±t, AraÃ§, Metro) ---
def fetch_ulasim():
    st.info("ğŸš— 4. UlaÅŸÄ±m verileri Ã§ekiliyor... (Petrol Ofisi & Ä°BB)")
    data = []
    
    # YakÄ±t
    po_url = "https://www.petrolofisi.com.tr/akaryakit-fiyatlari"
    soup = get_soup(po_url)
    if soup:
        rows = soup.find_all("tr", class_="price-row")
        if rows:
            cols = rows[0].find_all("td") # Ä°lk satÄ±r
            benzin = clean_price(cols[1].find("span").get_text())
            motorin = clean_price(cols[2].find("span").get_text())
            data.append({"Grup": "UlaÅŸÄ±m", "Kategori": "YakÄ±t", "ÃœrÃ¼n": "Benzin", "Fiyat": benzin})
            data.append({"Grup": "UlaÅŸÄ±m", "Kategori": "YakÄ±t", "ÃœrÃ¼n": "Motorin", "Fiyat": motorin})
            
    # Metro Ä°stanbul
    metro_url = "https://www.metro.istanbul/seferdurumlari/biletucretleri"
    s_metro = get_soup(metro_url)
    if s_metro:
        ul = s_metro.find("ul", class_="price2")
        if ul:
            li = ul.find("li")
            if li:
                p = li.find("span", class_="float-right").get_text()
                data.append({"Grup": "UlaÅŸÄ±m", "Kategori": "Toplu TaÅŸÄ±ma", "ÃœrÃ¼n": "Metro Tam Bilet", "Fiyat": clean_price(p)})
    
    # Manuel AraÃ§ FiyatlarÄ± (Senin koddan)
    data.append({"Grup": "UlaÅŸÄ±m", "Kategori": "AraÃ§", "ÃœrÃ¼n": "Hyundai i20", "Fiyat": 1256000.00})
    
    return pd.DataFrame(data)

# --- 5. DÄ°ÄER KATEGORÄ°LER (KÄ±sa KÄ±sa) ---
def fetch_diger():
    st.info("ğŸ’Š 5. SaÄŸlÄ±k, EÄŸitim ve DiÄŸerleri derleniyor...")
    data = []
    
    # SaÄŸlÄ±k (Manuel/Ã–rnek) - SelÃ§uk Ecza scraping Ã§ok spesifik, burada manuel geÃ§iyoruz senin kodundaki gibi de olabilir
    data.append({"Grup": "SaÄŸlÄ±k", "Kategori": "Ä°laÃ§", "ÃœrÃ¼n": "Aspirin", "Fiyat": 50.00}) # Ã–rnek
    
    # EÄŸitim (Manuel)
    data.append({"Grup": "EÄŸitim", "Kategori": "Okul", "ÃœrÃ¼n": "Ã–zel Okul (YÄ±llÄ±k)", "Fiyat": 380000.00})
    
    # Alkol/TÃ¼tÃ¼n (Manuel)
    data.append({"Grup": "Alkol/TÃ¼tÃ¼n", "Kategori": "Sigara", "ÃœrÃ¼n": "Marlboro", "Fiyat": 100.00})
    
    # Konut (Ä°SKÄ°/Ä°GDAÅ Manuel Ã–rnek - Kodunda scrape vardÄ± ama Ã§ok deÄŸiÅŸkendir)
    data.append({"Grup": "Konut", "Kategori": "Fatura", "ÃœrÃ¼n": "Su Birim Fiyat", "Fiyat": 32.50})
    
    return pd.DataFrame(data)

# --- ANA MOTOR ---

if st.button("ğŸš€ TÃœM VERÄ°LERÄ° GÃœNCELLE (ORÄ°JÄ°NAL MOD)", type="primary"):
    
    # TÃ¼m fonksiyonlarÄ± Ã§aÄŸÄ±r
    df1 = fetch_gida()
    df2 = fetch_giyim()
    df3 = fetch_ev()
    df4 = fetch_ulasim()
    df5 = fetch_diger()
    
    # BirleÅŸtir
    df_final = pd.concat([df1, df2, df3, df4, df5], ignore_index=True)
    
    st.success("Veri madenciliÄŸi tamamlandÄ±!")
    
    # BÃ¼yÃ¼k Rakam
    total = df_final["Fiyat"].sum()
    st.metric("Toplam Sepet DeÄŸeri (Ã‡ekilebilenler)", f"{total:,.2f} â‚º")
    
    # Tabloyu GÃ¶ster
    st.dataframe(
        df_final.style.format({"Fiyat": "{:.2f} â‚º"}),
        use_container_width=True,
        height=600
    )
    
    # Excel Ä°ndir
    csv = df_final.to_csv(index=False).encode('utf-8-sig')
    st.download_button("ğŸ“¥ Raporu Ä°ndir (CSV)", csv, "gercek_enflasyon.csv", "text/csv")

else:
    st.write("Verileri orijinal kaynaklarÄ±ndan (Onur Market, Flo, Koton, Petrol Ofisi, Ä°stikbal...) Ã§ekmek iÃ§in butona basÄ±n.")
    st.warning("Not: Bu iÅŸlem gerÃ§ek zamanlÄ± scraping yaptÄ±ÄŸÄ± iÃ§in sitelerin yanÄ±t verme sÃ¼resine gÃ¶re 30-60 saniye sÃ¼rebilir.")
